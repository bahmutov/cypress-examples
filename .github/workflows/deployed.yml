# Scrape deployed site into Algolia index
# https://glebbahmutov.com/blog/scrape-static-site-with-algolia/
name: deployed
on:
  status:
    branches:
      - master
jobs:
  scraped-site:
    if: github.event.context == 'github/pages' && github.event.state == 'success'
    runs-on: ubuntu-latest
    env:
      CYPRESS_baseUrl: https://glebbahmutov.com/cypress-examples
    steps:
      - run: echo "gh-pages ğŸ“‘ built successfully âœ…"

      # we need our scraping config, thus check out code
      - name: Checkout ğŸ›ï¸
        uses: actions/checkout@v2
        with:
          persist-credentials: false

      - name: Install dependencies ğŸ“¦
        uses: cypress-io/github-action@v1
        with:
          # just perform install
          runTests: false

      - name: Export Markdown specs ğŸ–¨
        run: ./md-to-js.sh $CYPRESS_baseUrl

      - name: Test deployed site ğŸ§ª
        uses: cypress-io/github-action@v1
        with:
          # we have already installed all dependencies above
          install: false
          config-file: cypress-dist.json

      - name: Semantic Release ğŸš€
        uses: cycjimmy/semantic-release-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}

      # when scraping the site, inject secrets as environment variables
      # then pass their values into the Docker container using "-e" syntax
      # and inject config.json contents as another variable
      - name: scrape the site ğŸ§½
        env:
          APPLICATION_ID: ${{ secrets.ALGOLIA_APPLICATION_ID }}
          API_KEY: ${{ secrets.ALGOLIA_API_KEY }}
        run: |
          docker run \
          -e APPLICATION_ID -e API_KEY \
          -e CONFIG="$(cat algolia-config.json)" \
          algolia/docsearch-scraper:v1.6.0
